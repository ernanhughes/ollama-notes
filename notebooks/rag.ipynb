{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ernanhughes/ollama-notes/blob/main/notebooks/rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = ''\n",
    "    with pymupdf.open(pdf_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69078\n"
     ]
    }
   ],
   "source": [
    "text = extract_text_from_pdf(\"2005.11401v4.pdf\")\n",
    "print(len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size, overlap=0):\n",
    "  \"\"\"\n",
    "  Splits text into chunks of specified length, ensuring words are not split.\n",
    "\n",
    "  Args:\n",
    "    text: The text to split.\n",
    "    chunk_size: The desired size of each chunk.\n",
    "    overlap: The number of characters to overlap between chunks. Defaults to 0.\n",
    "\n",
    "  Returns:\n",
    "    A list of text chunks.\n",
    "  \"\"\"\n",
    "\n",
    "  chunks = []\n",
    "  start = 0\n",
    "  while start < len(text):\n",
    "    # Find the next word boundary within the chunk size\n",
    "    end = start + chunk_size\n",
    "    if end >= len(text):\n",
    "      end = len(text)\n",
    "    else:\n",
    "      while end > start and text[end] != \" \" and end > start + overlap:\n",
    "        end -= 1\n",
    "\n",
    "    chunks.append(text[start:end])\n",
    "    start = end + overlap\n",
    "\n",
    "  return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_text(text, chunk_size=1024, overlap=128)\n",
    "ids = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    ids.append(f\"chunk_{i}\")\n",
    "\n",
    "print(len(chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "OLLAMA_EMBEDDING_MODEL=\"mxbai-embed-large\"\n",
    "OLLAMA_BASE_URL='http://127.0.0.1:11434'\n",
    "\n",
    "def generate_embeddings(text, model_name: str = OLLAMA_EMBEDDING_MODEL,\n",
    "                        base_url: str = OLLAMA_BASE_URL):\n",
    "    \"\"\"Generate embeddings for the given text using the specified model.\"\"\"\n",
    "    try:\n",
    "        url = f\"{base_url}/api/embeddings\"\n",
    "        data = {\n",
    "            \"prompt\": text,\n",
    "            \"model\": model_name\n",
    "        }\n",
    "        response = requests.post(url, json=data)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"embedding\"]\n",
    "        else:\n",
    "            print(f\"Failed to generate embeddings. Status code: {response.status_code}\")\n",
    "            print(\"Response:\", response.text)\n",
    "            return None\n",
    "    except requests.ConnectionError:\n",
    "        print(\"Failed to connect to the Ollama server. Make sure it is running locally and the URL is correct.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse JSON response from Ollama server.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('v0.1.3',)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlite3 import connect\n",
    "import sqlite_vec\n",
    "db_file = \"rag.db\"\n",
    "cn =connect(db_file)\n",
    "cur = cn.cursor()\n",
    "cn.enable_load_extension(True)\n",
    "sqlite_vec.load(cn)\n",
    "cn.enable_load_extension(False)\n",
    "ver = cur.execute(\"select vec_version()\").fetchone()\n",
    "ver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embeddings: 1024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings_len = 1024\n",
    "print(f\"Length of embeddings: {embeddings_len}\")\n",
    "create_table = f\"\"\"\n",
    "DROP TABLE IF EXISTS DOCUMENT_FTS;\n",
    "CREATE VIRTUAL TABLE DOCUMENT_FTS USING fts5(id UNINDEXED, content, tokenize=\"porter unicode61\");\n",
    "\n",
    "DROP TABLE IF EXISTS DOCUMENT_VECTOR;\n",
    "CREATE VIRTUAL TABLE DOCUMENT_VECTOR \n",
    "USING vec0(id INTEGER PRIMARY KEY, embedding float[{embeddings_len}]);\n",
    "\n",
    "DROP TABLE IF EXISTS DOCUMENT_LOOKUP;\n",
    "CREATE TABLE DOCUMENT_LOOKUP (id INTEGER PRIMARY KEY, content TEXT);\n",
    "\"\"\"\n",
    "cur.executescript(create_table)\n",
    "cn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def serialize_f32(vec):\n",
    "    return np.array(vec, dtype=np.float32).tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:02<00:00, 21.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cur.execute(\"DELETE FROM DOCUMENT_FTS;\")\n",
    "cur.execute(\"DELETE FROM DOCUMENT_VECTOR;\")\n",
    "cur.execute(\"DELETE FROM DOCUMENT_LOOKUP;\")\n",
    "\n",
    "i = 0\n",
    "for chunk in tqdm(chunks):\n",
    "    i += 1\n",
    "    embedding = generate_embeddings(chunk)\n",
    "    cur.execute(\"INSERT INTO DOCUMENT_FTS(id, content) VALUES (?, ?)\", (i, chunk))\n",
    "    cur.execute(\"INSERT INTO DOCUMENT_VECTOR(id, embedding) VALUES (?, ?)\", (i, serialize_f32(embedding)))\n",
    "    cur.execute(\"INSERT INTO DOCUMENT_LOOKUP(id, content) VALUES (?, ?)\", (i, chunk))\n",
    "cn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(fts_results, vec_results, k=60):  \n",
    "    rank_dict = {}  \n",
    "  \n",
    "    # Process FTS results  \n",
    "    for rank, (id,) in enumerate(fts_results):  \n",
    "        if id not in rank_dict:  \n",
    "            rank_dict[id] = 0  \n",
    "        rank_dict[id] += 1 / (k + rank + 1)  \n",
    "  \n",
    "    # Process vector results  \n",
    "    for rank, (rowid, distance) in enumerate(vec_results):  \n",
    "        if rowid not in rank_dict:  \n",
    "            rank_dict[rowid] = 0  \n",
    "        rank_dict[rowid] += 1 / (k + rank + 1)  \n",
    "  \n",
    "    # Sort by RRF score  \n",
    "    sorted_results = sorted(rank_dict.items(), key=lambda x: x[1], reverse=True)  \n",
    "    return sorted_results \n",
    "  \n",
    "def or_words(input_string):  \n",
    "    # Split the input string into words  \n",
    "    words = input_string.split()  \n",
    "      \n",
    "    # Join the words with ' OR ' in between  \n",
    "    result = ' OR '.join(words)  \n",
    "      \n",
    "    return result\n",
    "\n",
    "def lookup_row(id):\n",
    "    row_lookup = cur.execute('''  \n",
    "    SELECT content FROM DOCUMENT_LOOKUP WHERE id = ?\n",
    "    ''', (id,)).fetchall()  \n",
    "    content = ''\n",
    "    for row in row_lookup:\n",
    "        content= row[0]\n",
    "        break\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RDF Score</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>otland is Pound sterling.\\nRAG-T Pound is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>r 10 retrieved latent\\ndocuments, and we do no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>\\n77.8%\\n46.8%\\nRAG-Seq.\\n83.5%\\n53.8%\\nTable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>5\\n72.5\\n89.5\\nRAG-Seq. 14.7\\n21.4\\n40.8\\n44.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>-MARCO, where useful retrieved documents\\ncann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>eration,\\nwith both models outperforming BART ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>ce, and keep the document encoder (and\\nindex)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>ion signals aren’t available, and\\nmodels that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>g, we formally introduce both models and then ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  RDF Score                                            Content\n",
       "0  23   0.032266  otland is Pound sterling.\\nRAG-T Pound is the ...\n",
       "1  27   0.016393  r 10 retrieved latent\\ndocuments, and we do no...\n",
       "2  26   0.016129  \\n77.8%\\n46.8%\\nRAG-Seq.\\n83.5%\\n53.8%\\nTable ...\n",
       "3  19   0.016129  5\\n72.5\\n89.5\\nRAG-Seq. 14.7\\n21.4\\n40.8\\n44.2...\n",
       "4  59   0.015873  -MARCO, where useful retrieved documents\\ncann...\n",
       "5  20   0.015625  eration,\\nwith both models outperforming BART ...\n",
       "6  11   0.015625  ce, and keep the document encoder (and\\nindex)...\n",
       "7  17   0.015385  ion signals aren’t available, and\\nmodels that...\n",
       "8   8   0.015385  g, we formally introduce both models and then ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fts_search_query = \"RAG\" \n",
    "top_k = 5 \n",
    "\n",
    "fts_results = cur.execute('''  \n",
    "  SELECT id FROM DOCUMENT_FTS WHERE DOCUMENT_FTS MATCH ? \n",
    "  ORDER BY rank limit 5  \n",
    "''', (or_words(fts_search_query),)).fetchall()  \n",
    "  \n",
    "# Vector search query  \n",
    "query_embedding = generate_embeddings(fts_search_query)  \n",
    "vec_results = cur.execute('''  \n",
    "    SELECT id, distance FROM DOCUMENT_VECTOR \n",
    "    WHERE embedding MATCH ? and K = ?  \n",
    "    ORDER BY distance  \n",
    "''', [serialize_f32(query_embedding), top_k]).fetchall()  \n",
    "  \n",
    "# Combine results using RRF  \n",
    "combined_results = reciprocal_rank_fusion(fts_results, vec_results)  \n",
    "  \n",
    "df = pd.DataFrame(combined_results, columns=['ID', 'RDF Score'])\n",
    "\n",
    "row = []\n",
    "for id, _ in combined_results:  \n",
    "    row.append(lookup_row(id))\n",
    "\n",
    "df2 = pd.DataFrame(row, columns=['Content'])\n",
    "df = pd.concat([df, df2], axis=1)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
