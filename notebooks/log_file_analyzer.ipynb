{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you've created a simulated log file with various entries. I'll try to identify some patterns and anomalies.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "* The log contains a mix of \"log entry\" and \"error log entry\" messages.\n",
      "* There are 5 instances of the word \"test\".\n",
      "* The errors seem to be scattered throughout the log, but there's a higher frequency towards the end.\n",
      "* Some entries appear to be identical or nearly identical (e.g., multiple consecutive \"some other log entry\").\n",
      "\n",
      "**Possible interpretation:**\n",
      "\n",
      "This could represent a simplified simulation of a system log file over time. The \"log entry\" messages might indicate normal system operation, while the \"error log entry\" messages suggest issues or anomalies.\n",
      "\n",
      "The increased frequency of errors towards the end of the log could indicate a growing problem or a sudden spike in errors. The repeated \"test\" entries might represent some form of debugging or testing activity.\n",
      "\n",
      "Please let me know if this is an accurate interpretation or if you'd like to provide more context about what this log represents!"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def load_log(log_file_path:str = 'test.log', pre_lines:int = 5, post_lines:int = 5):\n",
    "  with open(log_file_path, 'r') as log_file:\n",
    "    log_lines = log_file.readlines()\n",
    "\n",
    "  error_logs = []\n",
    "  for i, line in enumerate(log_lines):\n",
    "      if \"error\" in line.lower():\n",
    "          start_index = max(0, i - pre_lines)\n",
    "          end_index = min(len(log_lines), i + post_lines + 1)\n",
    "          error_logs.extend(log_lines[start_index:end_index])\n",
    "\n",
    "  return error_logs\n",
    "\n",
    "error_logs = load_log()\n",
    "\n",
    "data = {\n",
    "  \"prompt\": \"\\n\".join(error_logs), \n",
    "  \"model\": \"llama3.1\",\n",
    "  \"options\": {\n",
    "     \"num_ctx\": 131072\n",
    "  }\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:11434/api/generate\", json=data, stream=True)\n",
    "for line in response.iter_lines():\n",
    "  if line:\n",
    "    json_data = json.loads(line)\n",
    "    if json_data['done'] == False:\n",
    "      print(json_data['response'], end='', flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
